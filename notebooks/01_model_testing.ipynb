{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de Teste de Modelos - Trackie\n",
    "\n",
    "Este notebook é usado para testar os serviços de visão computacional (YOLO, MiDaS, DeepFace) de forma isolada.\n",
    "\n",
    "**Instruções:**\n",
    "1.  Certifique-se de ter todas as dependências instaladas (`pip install -r requirements.txt`).\n",
    "2.  Coloque uma imagem de teste em `data/assets/test_image.jpg`.\n",
    "3.  Execute as células abaixo para ver os resultados de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Adiciona o diretório 'src' ao path para que possamos importar nossos módulos\n",
    "# Assumindo que o notebook está na pasta 'notebooks' na raiz do projeto\n",
    "project_root = Path(os.getcwd()).parent\n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Importa nossos serviços e configurações\n",
    "from trackie.config.settings import settings\n",
    "from trackie.services.vision.object_detector import ObjectDetector\n",
    "from trackie.services.vision.depth_estimator import DepthEstimator\n",
    "from trackie.services.vision.face_recognizer import FaceRecognizer\n",
    "\n",
    "# Converte as configurações para um dicionário para facilitar o uso\n",
    "settings_dict = settings.dict()\n",
    "\n",
    "# Caminho para a imagem de teste\n",
    "TEST_IMAGE_PATH = project_root / \"data/assets/test_image.jpg\"\n",
    "\n",
    "print(f\"Raiz do projeto: {project_root}\")\n",
    "print(f\"Imagem de teste: {TEST_IMAGE_PATH}\")\n",
    "\n",
    "# Helper para exibir imagens\n",
    "def show_image(img, title=\"Image\", cmap=None):\n",
    "    # Converte de BGR (OpenCV) para RGB (Matplotlib)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img_rgb, cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Teste do Detector de Objetos (YOLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o serviço de detecção de objetos\n",
    "try:\n",
    "    detector = ObjectDetector(settings_dict)\n",
    "    print(\"ObjectDetector carregado com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Falha ao carregar ObjectDetector: {e}\")\n",
    "    detector = None\n",
    "\n",
    "if detector:\n",
    "    # Carrega a imagem de teste\n",
    "    test_image = cv2.imread(str(TEST_IMAGE_PATH))\n",
    "    if test_image is None:\n",
    "        print(f\"Erro: Não foi possível carregar a imagem de {TEST_IMAGE_PATH}\")\n",
    "    else:\n",
    "        # Realiza a detecção\n",
    "        detections = detector.detect(test_image)\n",
    "        \n",
    "        # Desenha as detecções na imagem\n",
    "        annotated_image = test_image.copy()\n",
    "        if detections:\n",
    "            annotated_image = detections[0].plot() # O método .plot() do ultralytics é útil para visualização\n",
    "        \n",
    "        print(f\"Detecções encontradas: {len(detections[0].boxes) if detections else 0}\")\n",
    "        show_image(annotated_image, title=\"Resultados da Detecção YOLO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Teste do Estimador de Profundidade (MiDaS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o serviço de estimativa de profundidade\n",
    "try:\n",
    "    estimator = DepthEstimator(settings_dict)\n",
    "    print(\"DepthEstimator carregado com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Falha ao carregar DepthEstimator: {e}\")\n",
    "    estimator = None\n",
    "\n",
    "if estimator:\n",
    "    # Carrega a imagem de teste\n",
    "    test_image = cv2.imread(str(TEST_IMAGE_PATH))\n",
    "    if test_image is None:\n",
    "        print(f\"Erro: Não foi possível carregar a imagem de {TEST_IMAGE_PATH}\")\n",
    "    else:\n",
    "        # Estima a profundidade\n",
    "        depth_map = estimator.estimate(test_image)\n",
    "        \n",
    "        if depth_map is not None:\n",
    "            print(\"Mapa de profundidade gerado com sucesso.\")\n",
    "            # Exibe o mapa de profundidade\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.imshow(depth_map, cmap='gray')\n",
    "            plt.title(\"Mapa de Profundidade (MiDaS)\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Falha ao gerar o mapa de profundidade.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Teste do Reconhecimento Facial (DeepFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o serviço de reconhecimento facial\n",
    "try:\n",
    "    recognizer = FaceRecognizer(settings_dict)\n",
    "    print(\"FaceRecognizer carregado com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Falha ao carregar FaceRecognizer: {e}\")\n",
    "    recognizer = None\n",
    "\n",
    "if recognizer:\n",
    "    # Carrega a imagem de teste (deve conter um rosto)\n",
    "    face_image = cv2.imread(str(TEST_IMAGE_PATH))\n",
    "    if face_image is None:\n",
    "        print(f\"Erro: Não foi possível carregar a imagem de {TEST_IMAGE_PATH}\")\n",
    "    else:\n",
    "        print(\"Tentando identificar rostos na imagem de teste...\")\n",
    "        # Tenta identificar rostos na imagem contra o banco de dados existente\n",
    "        identified_dfs = recognizer.identify_faces(face_image)\n",
    "        \n",
    "        if not identified_dfs:\n",
    "            print(\"Nenhum rosto conhecido foi identificado na imagem.\")\n",
    "        else:\n",
    "            print(\"Rostos conhecidos identificados:\")\n",
    "            for df in identified_dfs:\n",
    "                print(df)\n",
    "        \n",
    "        show_image(face_image, title=\"Imagem de Teste para Reconhecimento Facial\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
